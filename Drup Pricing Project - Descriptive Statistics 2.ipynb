{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drug Pricing Project - Descriptive Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Packages and define arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import os\n",
    "import nltk\n",
    "import argparse\n",
    "import itertools\n",
    "import glob\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter, defaultdict, deque, OrderedDict\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from itertools import chain\n",
    "pd.options.display.max_colwidth = 450\n",
    "porter_stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/Users/jackiereimer/Dropbox/Drug Pricing Project/code/reddit_preprocessing')\n",
    "from reddit_preprocessing import reddit_preprocessing as rp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArgumentContainer(object):\n",
    "    def __init__(self):\n",
    "        self.data_folder = \"opiates\"\n",
    "        self.keyterm_folder = \"keyterm_lists\"\n",
    "        self.complete_threads_file = \"use_data/threads/all_dumps.csv\"\n",
    "        self.complete_comments_file = \"use_data/comments/all_comments.csv\"\n",
    "        self.stop_words = \"stop_words\"\n",
    "        self.location_folder = \"location\"\n",
    "        self.mat_folder = \"mat\"\n",
    "        self.unit_folder = \"unit\"\n",
    "        self.currency_folder = \"currency\"\n",
    "        self.output_folder = \"output\"\n",
    "        self.file_folder = None\n",
    "\n",
    "\n",
    "if 'args' not in dir():\n",
    "    args = ArgumentContainer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set filepaths and lists of keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All thread file: /Users/jackiereimer/Dropbox/drug_pricing_data/opiates/use_data/threads/all_dumps.csv\n",
      "All comment file: /Users/jackiereimer/Dropbox/drug_pricing_data/opiates/use_data/comments/all_comments.csv\n",
      "Stop Words file: /Users/jackiereimer/Dropbox/Drug Pricing Project/keyterm_lists/stop_words\n",
      "Locations file: /Users/jackiereimer/Dropbox/Drug Pricing Project/keyterm_lists/location\n",
      "MAT file: /Users/jackiereimer/Dropbox/Drug Pricing Project/keyterm_lists/mat\n",
      "Unit file: /Users/jackiereimer/Dropbox/Drug Pricing Project/keyterm_lists/unit\n",
      "Currency file: /Users/jackiereimer/Dropbox/Drug Pricing Project/keyterm_lists/currency\n",
      "Output folder: /Users/jackiereimer/Dropbox/Drug Pricing Project/keyterm_lists/output\n",
      "/Users/jackiereimer/Dropbox/Drug Pricing Project/keyterm_lists/location/state_init.csv\n",
      "/Users/jackiereimer/Dropbox/Drug Pricing Project/keyterm_lists/location/locations.csv\n",
      "/Users/jackiereimer/Dropbox/Drug Pricing Project/keyterm_lists/mat/naltrexone_words.csv\n",
      "/Users/jackiereimer/Dropbox/Drug Pricing Project/keyterm_lists/mat/suboxone_words.csv\n",
      "/Users/jackiereimer/Dropbox/Drug Pricing Project/keyterm_lists/mat/methadone_words.csv\n",
      "/Users/jackiereimer/Dropbox/Drug Pricing Project/keyterm_lists/mat/naloxone_words.csv\n",
      "/Users/jackiereimer/Dropbox/Drug Pricing Project/keyterm_lists/currency/currencies.csv\n",
      "/Users/jackiereimer/Dropbox/Drug Pricing Project/keyterm_lists/unit/quantity.csv\n",
      "/Users/jackiereimer/Dropbox/Drug Pricing Project/keyterm_lists/stop_words/stop_words.csv\n"
     ]
    }
   ],
   "source": [
    "locations_filepath, mat_filepath, all_comments_filepath, all_dumps_filepath, unit_filepath, currency_filepath, output_filepath, stopwords_filepath = rp.assign_location_dirs(args.data_folder, args.complete_threads_file, args.complete_comments_file, args.location_folder, args.mat_folder, args.unit_folder, args.currency_folder, args.output_folder, args.stop_words, args.file_folder)\n",
    "state_init, locations = rp.generates_non_case_sensitive_list_of_keyterms(locations_filepath)\n",
    "meth_words, sub_words, nalt_words, narc_words = rp.generates_non_case_sensitive_list_of_keyterms(mat_filepath)\n",
    "currencies = rp.generates_non_case_sensitive_list_of_keyterms(currency_filepath)[0]\n",
    "units = rp.generates_non_case_sensitive_list_of_keyterms(unit_filepath)[0]\n",
    "more_stops = rp.generates_non_case_sensitive_list_of_keyterms(stopwords_filepath)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 774 items within locations. After running the cell above, check the length to make sure that this is the case. If it is not, switch state_init and locations above and run again. This is the result of poor filepath generation that is not a big enough issue to warrant the amount of time that it would take to correct it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "774"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All r/opiates/ threads aggregated\n",
      "All r/opiates/ comments aggregated\n"
     ]
    }
   ],
   "source": [
    "total_thread_tuples, total_threads = rp.list_of_threads_from_csv(args.data_folder, all_dumps_filepath)\n",
    "total_comment_tuples, total_comments = rp.list_of_comments_from_csv(args.data_folder, all_comments_filepath)\n",
    "total_posts = total_threads + total_comments\n",
    "thread_tuples_headers = ['post_id','time','no_comments', 'post_title', 'post_body']\n",
    "comment_tuples_headers = ['comment_id', 'time', 'reply_id', 'post_body']\n",
    "stop = stopwords.words('english')\n",
    "stop_all = stop + more_stops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put Data into DataFrame and Define Regex Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_re = r\"^.*\\b({})\\b.*$\" # matches standalone strings\n",
    "digit_re = r\"\\s\\b\\d{1,3}\\b\" # matches standalone numbers between 1 and 3 digits\n",
    "price_re = r'^.*[{}]\\s?\\d{{1,3}}(?:[.,]\\d{{3}})*(?:[.,]\\d{{1,2}})?.*$' # matches standalone numbers of currency format with preceding currency symbol\n",
    "unit_price_re = r'[{}]?\\d+[/]\\D\\S+' # matches string of format 'digit(s)/letter(s)' (e.g. $40/gram, 5/mg)\n",
    "surrounding_dollar_re = r'(?P<before>(?:\\w+\\W+){5})\\$\\d+(?:\\.\\d+)?(?P<after>(?:\\W+\\w+){5})' # matches the five words that surround the mention of '$'\n",
    "surrounding_words_re = r'(?P<before>(?:\\w+\\W+){})[{}]\\d+(?:\\.\\d+)?(?P<after>(?:\\W+\\w+){})' # requires three inputs (digit, keywords, digit), matches the digit number of words that surround keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_key_word_threads_to_df(df, search_for, regexp, case_sensitive=False):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    print('Number of strings searched: %s' % df.shape[0])\n",
    "    print('Number of keywords searching for: %s' % len(search_for))\n",
    "    dt_start = datetime.datetime.now()\n",
    "    print('Starting time:', dt_start)\n",
    "    if not case_sensitive:\n",
    "        flag = re.I\n",
    "    else:\n",
    "        flag = False\n",
    "    i = 0\n",
    "    new_df = df\n",
    "    for keyword in search_for:\n",
    "        i += 1\n",
    "        print('Word %s out of %s' % (i, len(search_for)))\n",
    "        print('Time elapsed:', datetime.datetime.now() - dt_start)\n",
    "        word = re.compile(regexp.format(keyword), flags=flag)\n",
    "        new_df[keyword] = new_df.astype(str).sum(axis=1).str.contains(word, regex=True)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jackiereimer/beautifulsoup/lib/python3.6/site-packages/pandas/core/frame.py:6201: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=True'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass sort=False\n",
      "\n",
      "  sort=sort)\n"
     ]
    }
   ],
   "source": [
    "comment_df = pd.DataFrame(total_comment_tuples, columns=comment_tuples_headers)\n",
    "thread_df = pd.DataFrame(total_thread_tuples, columns=thread_tuples_headers)\n",
    "reddit_df = thread_df.append(comment_df)\n",
    "reddit_df = reddit_df[['time', 'post_id', 'reply_id', 'no_comments', 'comment_id', 'post_title', 'post_body']]\n",
    "#reddit_df = reddit_df.applymap(lambda s:s.lower() if type(s) == str else s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_df['time_new'] = pd.to_datetime(comment_df['time'], unit='s')\n",
    "comment_df['date'] = comment_df['time_new'].dt.date\n",
    "comment_df['time_new'] = pd.to_datetime(comment_df['time'], unit='s')\n",
    "comment_df['time'] = pd.to_numeric(comment_df['time'])\n",
    "comment_df['date'] = pd.to_datetime(comment_df['time_new'])\n",
    "\n",
    "thread_df['time_new'] = pd.to_datetime(thread_df['time'], unit='s')\n",
    "thread_df['date'] = thread_df['time_new'].dt.date\n",
    "thread_df['time_new'] = pd.to_datetime(thread_df['time'], unit='s')\n",
    "thread_df['time'] = pd.to_numeric(thread_df['time'])\n",
    "thread_df['date'] = pd.to_datetime(thread_df['time_new'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "comment_df.time = pd.to_datetime(comment_df.time, unit='s')\n",
    "thread_df.time = pd.to_datetime(thread_df.time, unit='s')\n",
    "#year_count = pd.DataFrame(thread_df['time'].resample('Y').count())\n",
    "comment_count = pd.DataFrame(comment_df['comment_id'].resample('Y').count(), columns = year_count_headers)\n",
    "#result = pd.merge(year_count, comment_count, on='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Threads</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-12-31 00:00:00</th>\n",
       "      <td>42.0</td>\n",
       "      <td>359.0</td>\n",
       "      <td>401.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-12-31 00:00:00</th>\n",
       "      <td>270.0</td>\n",
       "      <td>3705.0</td>\n",
       "      <td>3975.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-31 00:00:00</th>\n",
       "      <td>3403.0</td>\n",
       "      <td>63412.0</td>\n",
       "      <td>66815.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-31 00:00:00</th>\n",
       "      <td>7656.0</td>\n",
       "      <td>150472.0</td>\n",
       "      <td>158128.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 00:00:00</th>\n",
       "      <td>11450.0</td>\n",
       "      <td>207922.0</td>\n",
       "      <td>219372.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-31 00:00:00</th>\n",
       "      <td>13700.0</td>\n",
       "      <td>249304.0</td>\n",
       "      <td>263004.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-31 00:00:00</th>\n",
       "      <td>18834.0</td>\n",
       "      <td>331180.0</td>\n",
       "      <td>350014.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-31 00:00:00</th>\n",
       "      <td>32056.0</td>\n",
       "      <td>471394.0</td>\n",
       "      <td>503450.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31 00:00:00</th>\n",
       "      <td>65227.0</td>\n",
       "      <td>358684.0</td>\n",
       "      <td>423911.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>152638.0</td>\n",
       "      <td>1836432.0</td>\n",
       "      <td>1989070.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Threads   Comments      Total\n",
       "time                                               \n",
       "2010-12-31 00:00:00      42.0      359.0      401.0\n",
       "2011-12-31 00:00:00     270.0     3705.0     3975.0\n",
       "2012-12-31 00:00:00    3403.0    63412.0    66815.0\n",
       "2013-12-31 00:00:00    7656.0   150472.0   158128.0\n",
       "2014-12-31 00:00:00   11450.0   207922.0   219372.0\n",
       "2015-12-31 00:00:00   13700.0   249304.0   263004.0\n",
       "2016-12-31 00:00:00   18834.0   331180.0   350014.0\n",
       "2017-12-31 00:00:00   32056.0   471394.0   503450.0\n",
       "2018-12-31 00:00:00   65227.0   358684.0   423911.0\n",
       "Total                152638.0  1836432.0  1989070.0"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_year_count = pd.DataFrame(comment_df.set_index('time').resample('Y').size())\n",
    "comment_year_count.rename_axis('Year')\n",
    "\n",
    "thread_year_count = pd.DataFrame(thread_df.set_index('time').resample('Y').size())\n",
    "thread_year_count.rename_axis('Year')\n",
    "\n",
    "result = pd.merge(thread_year_count, comment_year_count, on='time')\n",
    "mapping = {result.columns[0]:'Threads', result.columns[1]: 'Comments'}\n",
    "result['Total'] = result.sum(axis=1)\n",
    "result.loc['Total',:]= result.sum(axis=0)\n",
    "result.rename(columns=mapping)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
