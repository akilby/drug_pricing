{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "import spacy\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en', disable=['parser', 'ner'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[tutorial i followed](https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/#7removeemailsandnewlinecharacters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = pd.datetime.today().date()\n",
    "today_str = str(today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = pd.read_csv('/projects/2016-01-911analytics/write_data/lda_test_2020_01_22/cfd_attributed_events.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags = pd.read_csv('/projects/2016-01-911analytics/write_data/lda_test_2020_01_22/attributed_events_detail_descriptor_flags.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_columns = [\n",
    "    'complaint',\n",
    "    'medications',\n",
    "    'symptom',\n",
    "    'hxpresent_comments',\n",
    "    'impression',\n",
    "    'preexisting',\n",
    "    'result_comments',\n",
    "    'incident_type',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events[text_columns].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "concatentate text fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (\n",
    "    events[text_columns]\n",
    "#     .sample(10000, random_state=1)\n",
    "    .replace(np.nan, '')\n",
    "    .astype(str)\n",
    "    .apply(' '.join, axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " clean and tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_series(s):\n",
    "    return (\n",
    "        s\n",
    "#         simple_preprocess does all these for us\n",
    "#         .str.strip()\n",
    "#         .str.lower()\n",
    "#         .str.replace(r'[^A-Za-z0-9 ]', '')\n",
    "#         .str.replace(r'\\s+', ' ')\n",
    "        .apply(simple_preprocess, deacc=True)\n",
    "        .apply(np.array)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = clean_text_series(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text.iat[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_en = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### what's the fastest way?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords_np(t, stopwords=stopwords_en):\n",
    "    return t[~np.isin(t, stopwords_en)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords_lc(t, stopwords=stopwords_en):\n",
    "    return [w for w in t if w not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "text.apply(remove_stopwords_np, stopwords=np.array(stopwords_en))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "text.apply(remove_stopwords_lc, stopwords=set(stopwords_en))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_stopwords = remove_stopwords_np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now back to reality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text.apply(remove_stopwords_lc, stopwords=set(stopwords_en))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(t, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    return [token.lemma_ for token in nlp(' '.join(t)) if token.pos_ in allowed_postags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text.apply(lemmatize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = corpora.Dictionary(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word.filter_extremes(no_below=100, no_above=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = text.apply(id2word.doc2bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_topics = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.ldamodel.LdaModel(\n",
    "    corpus=corpus,\n",
    "    id2word=id2word,\n",
    "    num_topics=n_topics, \n",
    "    random_state=100,\n",
    "    update_every=1,\n",
    "    chunksize=1000,\n",
    "    passes=10,\n",
    "    alpha='auto',\n",
    "    per_word_topics=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'lda-{today_str}.pkl', 'wb') as f:\n",
    "    pickle.dump(lda_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyLDAvis.enable_notebook()\n",
    "# vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
    "# vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = (\n",
    "    pd.DataFrame(\n",
    "        lda_model.show_topics(formatted=False, num_topics=n_topics)\n",
    "    )\n",
    "    .explode(1)\n",
    "    .rename(columns={0: 'topic', 1: 'word'})\n",
    ")\n",
    "topics['value'] = topics.word.apply(lambda x: x[1])\n",
    "topics['word'] = topics.word.apply(lambda x: x[0])\n",
    "topics = topics.sort_values(['topic', 'value'], ascending=[1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics.to_csv('topics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "least_word = topics.reset_index().word.at[topics.reset_index().value.idxmin()]\n",
    "text.apply(lambda x: least_word in x).sum(), least_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics['rank'] = topics.groupby('topic').agg({'value': 'rank'}).add(-11).multiply(-1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics.pivot('topic', 'rank', 'word').reset_index().to_csv('topics_wide.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- histograms of what probabilities are over all documents for each topic\n",
    "- correlation matrix between existing flags and topics\n",
    "- set threshold for topic 1-0\n",
    "    - try also correlation with topic probability\n",
    "- flags: projects/2016-01-911analytics/write_data/2016_05_01_to_2017_04_30_dob_ref_2016_05_01/CFD/cfd_attributed_events_detail_descriptor_flags.RData\n",
    "- how many events are assigned to each topic?\n",
    "- how many individuals are assigned to each topic?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model.show_topics(num_topics=n_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_topics = corpus.apply(lda_model.get_document_topics, minimum_probability=0).explode()\n",
    "document_topics = pd.DataFrame({'topic': document_topics.apply(lambda x: x[0]), 'probability': document_topics.apply(lambda x: x[1])})\n",
    "document_topics = document_topics.pivot(columns='topic', values='probability')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_topics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this means we can just concat\n",
    "(events.unique_id == flags.unique_id).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_cols = document_topics.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_cols = flags.columns.difference(['unique_id', 'key_case', 'month_yr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full = pd.concat([document_topics, flags[flag_cols]], axis=1).corr().reindex(index=topic_cols, columns=flag_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(21, 7))\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "sns.heatmap(full, ax=ax, cmap=cmap, vmin=-1, vmax=1)\n",
    "ax.set_title('Correlation plot of topic probability with flag indicator')\n",
    "ax.set_xlabel('flag')\n",
    "ax.set_ylabel('topic')\n",
    "fig.savefig('heatmap.png', dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
